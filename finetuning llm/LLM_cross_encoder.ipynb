{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 1. JSON 파일 로드\n",
    "with open(\"qa_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# JSON 데이터를 데이터프레임으로 변환\n",
    "df_qa_test = pd.DataFrame(qa_data)\n",
    "\n",
    "# 2. 이미 파인튜닝된 모델과 토크나이저 사용\n",
    "# 모델과 토크나이저는 이미 로드된 상태로 가정 (model, tokenizer)\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)  # `device` 인수 제거\n",
    "\n",
    "# 3. CrossEncoder 로드\n",
    "cross_encoder_model_name = \"BAAI/bge-reranker-v2-m3\"  # CrossEncoder 모델 이름\n",
    "cross_encoder = CrossEncoder(cross_encoder_model_name)\n",
    "\n",
    "# 4. 예측값 생성 및 성능 평가 함수\n",
    "def cross_encoder_evaluate_qa_dataset(df_qa_test):\n",
    "    \"\"\"\n",
    "    QA 데이터셋에 대해 LLM으로 예측값을 생성하고 CrossEncoder로 유사도를 평가합니다.\n",
    "\n",
    "    Args:\n",
    "    df_qa_test (pd.DataFrame): 평가할 QA 데이터셋\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: 질문, 실제 답변, 예측 답변, 유사도 점수를 포함한 결과 데이터프레임\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(df_qa_test)):\n",
    "        question = df_qa_test.iloc[i]['question']\n",
    "        ground_truth = df_qa_test.iloc[i]['answer']\n",
    "\n",
    "        # 파인튜닝된 모델을 사용해 예측값 생성\n",
    "        prediction = llm_pipeline(question, max_new_tokens=100, num_return_sequences=1)[0][\"generated_text\"]\n",
    "\n",
    "        # 유사도 점수 계산\n",
    "        similarity = cross_encoder.predict([[ground_truth, prediction]])[0]\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"prediction\": prediction,\n",
    "            \"similarity\": f\"{similarity:.3f}\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 5. 평가 수행\n",
    "df_result_cross_encoder = cross_encoder_evaluate_qa_dataset(df_qa_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 정리 함수 (인덱스와 유사도만 데이터프레임으로 반환)\n",
    "def get_similarity_results(df_result):\n",
    "    \"\"\"\n",
    "    평가 결과에서 인덱스와 유사도만 정리하여 데이터프레임으로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "    df_result (pd.DataFrame): 평가 결과 데이터프레임\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: 인덱스와 유사도만 포함된 데이터프레임\n",
    "    \"\"\"\n",
    "    # 필요한 열만 선택\n",
    "    if \"index\" in df_result.columns and \"similarity\" in df_result.columns:\n",
    "        selected_columns = [\"index\", \"similarity\"]\n",
    "        df_similarity = df_result[selected_columns]\n",
    "        return df_similarity\n",
    "    else:\n",
    "        raise KeyError(\"The required columns 'index' and 'similarity' are not found in the dataframe.\")\n",
    "\n",
    "# 평가 수행 (예시 데이터프레임 사용)\n",
    "# df_qa_test: QA 테스트 데이터프레임\n",
    "# cross_encoder_evaluate_qa_dataset: QA 평가 함수\n",
    "# 예제 데이터를 사용하거나 아래 코드를 실행 전에 데이터 준비가 필요합니다.\n",
    "try:\n",
    "    # 평가 수행 결과\n",
    "    df_result_cross_encoder = cross_encoder_evaluate_qa_dataset(df_qa_test)\n",
    "\n",
    "    # 결과 데이터프레임 생성\n",
    "    df_similarity_results = get_similarity_results(df_result_cross_encoder)\n",
    "\n",
    "    # 결과 데이터프레임 출력\n",
    "    df_similarity_results\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity_results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
